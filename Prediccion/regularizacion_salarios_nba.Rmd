---
title: "PRACTICA NBA REGULARIZACION"
author: "JAVIER BARTOLOMÉ RODRÍGUEZ"
date: "15/10/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## LIBRERIAS NECESARIA PARA EL DESARROLLO DE LA PRACTICA ##

```{r}
library(rsample)
library(glmnet) 
library(dplyr)  
library(ggplot2)
library(nortest)
library(readr)
library(ISLR)
library(leaps)
```

## IMPORTACION DE DATOS UBICADOS EN NUESTRO ORDENADOR ##

```{r}
ubicacion_datos <- "C:/Users/jbart/OneDrive/Escritorio/CUNEF/Predicción/TAREAS/TAREA 2/nba.csv"

datos_nba <- read_csv(ubicacion_datos)

```

## RENONBRAMOS LAS VARIABLES PARA NUESTRA COMODIDAD ##

```{r}
datos_nba<-rename(datos_nba,"Jugador"="Player","Salario"="Salary",'Pais'='NBA_Country','Numero_Draft'="NBA_DraftNumber", "Edad"="Age", "Equipo"="Tm", "Partidos_Jugados"="G", "Minutos_Jugados"="MP", "Eficiencia_Jugador"="PER", "Acierto_Tiro"="TS%", "Intento_Triples"="3PAr", "Intento_Libres"="FTr", "Rebotes_Ofensivos"="ORB%", "Rebotes_Defensivos"="DRB%", "Rebotes_Totales"="TRB%", "Asistencias"="AST%", "Steals"="STL%" , "Chapas"="BLK%", "Perdidas_Balon"="TOV%", "Victorias_Ofensivas"="OWS", "Victorias_Defensivas"="DWS", "Puntos_OfensivosVSMedia"="OBPM", "Puntos_DefensivosVSMedia"="DBPM", "PuntosVSMedia"="BPM", "PuntosVSMedia_Competidor_Directo"="VORP")

```

## COMPROBAMOS CUANTAS VARIABLES TENEMOS INUTILIZABLES ##

```{r}

1 - (sum(complete.cases(datos_nba)) / nrow(datos_nba))
```

## ELIMINAMOS LAS VARIABLES DUPLICADAS Y LOS NA ##

```{r}
datos_nba <- unique(datos_nba)

datos_nba <- na.omit(datos_nba)
```

## BEST SUBSET SELECTION ##

#Muestra de nombres

```{r}
names(datos_nba)
```

#Tipos de variables

```{r}
str(datos_nba)
```

## DIMENSION DATOS ##

```{r}
dim(datos_nba)
```

## MODELOS PREDICTIVOS ##

```{r}
mejor_modelo <- regsubsets(Salario~.- Jugador - Pais - Equipo, data = datos_nba, nvmax = 24)
summary(mejor_modelo)
```

## Una vez identificado el mejor modelo de cada tamaño, se tiene que escoger el mejor de entre todos ellos. ##

```{r}
names(summary(mejor_modelo))
```
## HACEROS EL ADJUST SQUARE ERROR, CUANTO MAS ALTO MEJOR ##

```{r}
summary(mejor_modelo)$adjr2
```

#Se identifica que modelo tiene el valor máximo de R ajustado

```{r}
which.max(summary(mejor_modelo)$adjr2)
```

## REPRESENTACION GRAFICA DEL ESTADISTICOESCOGIDO PARA COMPARAR LOS MODELOS ##

```{r}
p <- ggplot(data = data.frame(n_predictores = 1:24,
                              R_ajustado = summary(mejor_modelo)$adjr2),
            aes(x = n_predictores, y = R_ajustado)) +
    geom_line() +
    geom_point()

#Se identifica en rojo el máximo
p <- p + geom_point(aes(
                    x = n_predictores[which.max(summary(mejor_modelo)$adjr2)],
                    y = R_ajustado[which.max(summary(mejor_modelo)$adjr2)]),
                    colour = "red", size = 3)
p <- p +  scale_x_continuous(breaks = c(0:24)) + 
          theme_bw() +
          labs(title = 'R2_ajustado vs número de predictores', 
               x =  'número predictores')
p

```

## COEFICIENTES DEL MODELO Y SU ESTIMACION ##

```{r}
coef(object = mejor_modelo, id = 11)
summary(mejor_modelo)$adjr2[5]
```

## K-CROSS-VALIDATION ##

```{r}
set.seed(11)
# Sample() mezcla aleatoriamente las posiciones
# Es importante que la asignación sea aleatoria
grupo <- sample(rep(x = 1:10, length = nrow(datos_nba))) 

#Se comprueba que la distribución es aproximadamente equitativa
table(grupo)
```

## PREDICCIONES DE CADA UNO DE LOS MODELOS ##

```{r}
predict.regsubsets  <- function(object, newdata, id, ...){
    # Extraer la fórmula del modelo (variable dependiente ~ predictores)
    form <- as.formula(object$call[[2]])
    # Generar una matriz modelo con los nuevos datos y la fórmula
    mat <- model.matrix(form, newdata)
    # Extraer los coeficientes del modelo
    coefi <- coef(object , id = id)
    # Almacenar el nombre de las variables predictoras del modelo
    xvars <- names(coefi)
    # Producto matricial entre los coeficientes del modelo y los valores de
    # los predictores de las nuevas observaciones para obtener las 
    # predicciones
    mat[ , xvars] %*% coefi
}


# Matriz que almacena los test-error estimados. Cada columna representa un
# modelo. Cada fila representa uno de los 10 grupos en los que se han dividido
# las observaciones.
error_matrix <- matrix(data = NA, nrow = 10, ncol = 24,
                       dimnames = list(NULL, c(1:24)))

# Loop en el que se excluye en cada iteración un grupo distinto
# ESTE LOOP ESTA HECHO PARA UN DATA FRAME CON 19 PREDICTORES
num_validaciones <- 10
num_predictores <- 24

for (k in 1:num_validaciones) {
  # Identificación de datos empleados como training
  train <- datos_nba[grupo != k, ]
  # Selección de los mejores modelos para cada tamaño basándose en RSS
  mejor_modelo <- regsubsets(Salario~. - Jugador - Pais - Equipo, data = train, nvmax = 24,
                                method = "forward")
 
  # Para cada uno de los modelos "finalistas" se calcula el test-error con
  # el grupo excluido
  for (i in 1:num_predictores) {
    test <- datos_nba[grupo == k, ]
    # Las predicciones del modelo i almacenado en el objeto regsubsets se
    # extraen mediante la función predict.regsubsets() definida arriba
    predicciones <- predict.regsubsets(object = mejor_modelo,
                                       newdata = test, id = i)
    # Cálculo y almacenamiento del MSE para el modelo i
    error_matrix[k,i] <- mean((test$Salario - predicciones)^2)
  }
}
```



```{r}
mean_cv_error <- apply(X = error_matrix, MARGIN = 2, FUN = mean)
# plot(sqrt(mean_cv_error), type = "b", pch = 24)
which.min(x = mean_cv_error)
```
```{r}

ggplot(data = data.frame(n_predictores = 1:24, mean_cv_error = mean_cv_error),
       aes(x = n_predictores, y = mean_cv_error)) +
  geom_line() +
  geom_point() +
  geom_point(aes(x = n_predictores[which.min(mean_cv_error)],
                 y = mean_cv_error[which.min(mean_cv_error)]),
             colour = "red", size = 3) +
  scale_x_continuous(breaks = c(0:19)) +
  theme_bw() +
  labs(title = "Cross-validation mean error vs número de predictores",
       x = "número predictores")


```

## EL MEJOR MODELO POR 10 CROSS VALIDATION ESTA FORMADO POR 8 PREDICTORES ##

```{r}
modelo_final <- regsubsets(Salario~. -Jugador -Pais -Equipo, data = datos_nba, nvmax = 24,
                           method = "forward")
coef(object = modelo_final, 8)
```

## ELASTIC NET ##

```{r}
set.seed(123)
nba_split <- initial_split(datos_nba, prop = .7, strata = "Salario")
nba_train <- training(nba_split)
nba_test  <- testing(nba_split)
```


```{r}
# Creamos las matrices de entrenamiento y test
nba_train_x <- model.matrix(Salario ~ .-Jugador -Pais -Equipo, nba_train)[, -1]
nba_train_y <- nba_train$Salario

nba_test_x <- model.matrix(Salario ~ .-Jugador -Pais -Equipo, nba_test)[, -1]
nba_test_y <- nba_test$Salario

# Vemos la dimension de la matriz
dim(nba_train_x)

```

## Elastic Nets


```{r}

#Implementación y graficación
lasso    <- glmnet(nba_train_x, nba_train_y, alpha = 1.0) 
elastic1 <- glmnet(nba_train_x, nba_train_y, alpha = 0.25) 
elastic2 <- glmnet(nba_train_x, nba_train_y, alpha = 0.75) 
ridge    <- glmnet(nba_train_x, nba_train_y, alpha = 0.0)

par(mfrow = c(2, 2), mar = c(6, 4, 6, 2) + 0.1)
plot(lasso, xvar = "lambda", main = "Lasso (Alpha = 1)\n\n\n")
plot(elastic1, xvar = "lambda", main = "Elastic Net (Alpha = .25)\n\n\n")
plot(elastic2, xvar = "lambda", main = "Elastic Net (Alpha = .75)\n\n\n")
plot(ridge, xvar = "lambda", main = "Ridge (Alpha = 0)\n\n\n")

#Tuning : alpha y lambda
fold_id <- sample(1:10, size = length(nba_train_y), replace = TRUE)

tuning_grid <- tibble::tibble(
  alpha      = seq(0, 1, by = 0.01),
  mse_min    = NA,
  mse_1se    = NA,
  lambda_min = NA,
  lambda_1se = NA
)

#Preparamos la Cross Validation y asignamos lambdas
for (i in seq_along(tuning_grid$alpha)) {
  fit <- cv.glmnet(nba_train_x, nba_train_y, alpha = tuning_grid$alpha[i], foldid = fold_id)
  
  tuning_grid$mse_min[i]    <- fit$cvm[fit$lambda == fit$lambda.min]
  tuning_grid$mse_1se[i]    <- fit$cvm[fit$lambda == fit$lambda.1se]
  tuning_grid$lambda_min[i] <- fit$lambda.min
  tuning_grid$lambda_1se[i] <- fit$lambda.1se
}

tuning_grid

tuning_grid %>%
  mutate(se = mse_1se - mse_min) %>%
  ggplot(aes(alpha, mse_min)) +
  geom_line(size = 2) +
  geom_ribbon(aes(ymax = mse_min + se, ymin = mse_min - se), alpha = .25) +
  ggtitle("MSE ± one standard error")

#Elegimos el mejor modelo
cv_lasso   <- cv.glmnet(nba_train_x, nba_train_y, alpha = 1)
min(cv_lasso$cvm)


#Se hace la predicción
pred <- predict(cv_lasso, s = cv_lasso$lambda.min, nba_test_x)
errorobtenido <- sqrt(mean((nba_test_y - pred)^2))
errorobtenido
```

## FIN ##
